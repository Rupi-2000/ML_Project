# DocLayNet Data Pipeline ğŸ“„â¡ï¸ğŸ“Š

Dieses Repository stellt eine **reproduzierbare Datenpipeline** zur Vorbereitung des [DocLayNet-Datensatzes](https://github.com/DS4SD/DocLayNet) fÃ¼r **multimodales Training** bereit. Es verarbeitet sowohl

* **visuelle Layout-Daten** (fÃ¼r YOLOv8) als auch
* **reine Textdaten** (fÃ¼r NLP / Dokumentklassifikation)

und stellt sicher, dass **identische Train/Val/Test-Splits** in beiden ModalitÃ¤ten verwendet werden (Vermeidung von Data Leakage).

---

## ğŸš€ Features

* **Automatischer Download**
  LÃ¤dt die *Core*- und *Extra*-DatensÃ¤tze automatisiert herunter und entpackt sie.

* **YOLOv8-kompatibles Format**
  Konvertiert COCO-Annotationen (Bounding Boxes) in das YOLO-Format.

* **Parallele Textextraktion (Multiprocessing)**
  Extrahiert Textinhalte aus den JSON-Dateien des Extra-Datensatzes und speichert sie als CSV. Nutzt alle verfÃ¼gbaren CPU-Kerne (I/O- und CPU-optimiert).

* **Konsistente Datensplits**
  Garantiert, dass Dokumente im Vision-Training exakt denselben Splits (Train/Val/Test) im Text-Datensatz zugeordnet sind.

---

## ğŸ“‚ Ordnerstruktur (Output)

Nach erfolgreicher AusfÃ¼hrung aller Skripte ergibt sich folgende Struktur:

```text
data/
â”œâ”€â”€ doclaynet_core/        # Original-Download (Bilder & COCO-JSONs)
â”œâ”€â”€ doclaynet_extra/       # Original-Download (Text-JSONs)
â”œâ”€â”€ yolo_dataset/          # Output fÃ¼r Vision-Modelle (YOLOv8)
â”‚   â”œâ”€â”€ train/             # images/ & labels/
â”‚   â”œâ”€â”€ val/
â”‚   â””â”€â”€ test/
â””â”€â”€ text_dataset/          # Output fÃ¼r Text-Modelle
    â”œâ”€â”€ train.csv
    â”œâ”€â”€ val.csv
    â””â”€â”€ test.csv
```

---


## ğŸ”§ Installation

```bash
# Repository klonen
git clone https://github.com/Rupi-2000/ML_Project.git
cd ML_Project
```
---

## ğŸ§ª Environment Setup (Recommended)

Empfohlen wird die Verwendung eines Python Virtual Environments zur
GewÃ¤hrleistung der Reproduzierbarkeit.

**Python-Version:** â‰¥ 3.12 (getestet mit Python 3.12.12)

```bash
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install --upgrade pip

# Pipeline A (Text)
pip install -e .[core]

# Pipeline B + C (Text + Vision)
pip install -e .[core,vision]

# Alles inkl. Entwicklung
pip install -e .[core,vision,dev]
```
The required dependencies are defined in pyproject.toml.

---

## Wichtiger Hinweis (Torch & CUDA)

Absichtlich nicht in TOML enthalten:

```bash
# CPU
pip install torch torchvision torchaudio

# CUDA (z. B. 12.1)
pip install torch torchvision torchaudio \
  --index-url https://download.pytorch.org/whl/cu121
```

â¡ï¸ Das ist Best Practice, besonders bei Python 3.12.

---

## âš™ï¸ Nutzung (Schritt-fÃ¼r-Schritt)

Die Skripte **mÃ¼ssen in der angegebenen Reihenfolge** ausgefÃ¼hrt werden.

---

### 1ï¸âƒ£ Daten herunterladen

LÃ¤dt `DocLayNet_core.zip` und `DocLayNet_extra.zip` herunter und entpackt beide DatensÃ¤tze.

âš ï¸ **Hinweis:** Es werden ca. **30â€¯GB+ Speicherplatz** benÃ¶tigt.

```bash
python prepare_data.py
```

---

### 2ï¸âƒ£ Vision-Daten vorbereiten (YOLO)

Konvertiert die originalen COCO-Annotationen (`train.json`, `val.json`, `test.json`) in das YOLO-Format und kopiert die zugehÃ¶rigen Bilder in die entsprechenden Ordner.

```bash
python prepare_core_yolo.py
```

**Output:**

```
data/yolo_dataset/
```
Erstelle eine (`data.yaml`) Datei und fÃ¼ge den Output von Terminal ein!

---

### 3ï¸âƒ£ Text-Daten vorbereiten (CSV)

Verarbeitet die Text-JSON-Dateien aus dem *Extra*-Datensatz. Die Dokumente werden anhand der Dateinamen den Core-Splits (Train/Val/Test) zugeordnet.

**Optimierung:**
Verwendet `ProcessPoolExecutor`, um tausende Dateien parallel zu verarbeiten.

```bash
python prepare_extra_text.py
```

**Output:**

```
data/text_dataset/train.csv
data/text_dataset/val.csv
data/text_dataset/test.csv
```

---

### 4ï¸âƒ£ Klassenverteilung prÃ¼fen (optional)

Gibt Statistiken zur Klassenverteilung der erzeugten CSV-Dateien aus, um mÃ¶gliche Unwuchten frÃ¼hzeitig zu erkennen.

```bash
python check_class_distro_text_df.py
```

---

## ğŸ“Š Dokumentklassen

Die Pipeline verarbeitet und filtert **6 Dokumentenkategorien**:

* Financial Reports
* Scientific Articles
* Laws & Regulations
* Government Tenders
* Manuals
* Patents

---

## ğŸ§© Layout-Klassen (YOLO)

FÃ¼r den Vision-Teil werden **11 Layout-Klassen** extrahiert:

* Caption
* Footnote
* Formula
* List-item
* Page-footer
* Page-header
* Picture
* Section-header
* Table
* Text
* Title

---

## ğŸ“ Lizenz & Referenz

Der DocLayNet-Datensatz wurde von **IBM Research** verÃ¶ffentlicht. Bitte beachte die Lizenzbedingungen des Originaldatensatzes:

* **Lizenz:** CDLA-Permissive-1.0

**Paper:**
*DocLayNet: A Large Human-Annotated Dataset for Document-Layout Analysis* (KDD 2022)
